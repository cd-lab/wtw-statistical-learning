}
dev.off()
# save group AUC results
outFileName = file.path(figDir, sprintf('grp_n%d_groupAUC.csv', n))
write.csv(grpAUC, file=outFileName, row.names=FALSE)
grpAUC
AUCResults <- merge(grpAUC, dataSummary, by.x = "IDs")
AUCResults <- merge(grpAUC, dataSummary, by.x = "IDs")
table(AUCResults$b1_timingCond)
nHP <- as.numeric(table(AUCResults$b1_timingCond)[1])
nLP <- as.numeric(table(AUCResults$b1_timingCond)[2])
describeBy(AUCResults$AUC, AUCResults$b1_timingCond)
View(AUCResults)
View(AUCResults)
# AUC smaller than 2.16
AUCResults$smaller216 <- rep(0, nrow(AUCResults))
AUCResults$smaller216
# AUC smaller than 2.16
AUCResults$smaller216 <- rep(0, nrow(AUCResults))
which(AUCResults$AUC < 2.16)
AUCResults$smaller216[which(AUCResults$AUC < 2.16)] <- 1
AUCResults$check <- AUCResults$AUC
subset(AUCResults, AUCResults$smaller216 == 0 )
AUCResults <- subset(AUCResults, AUCResults$smaller216 == 0 )
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIincongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")])
# LP t-test and Bayes factor
ttestLP <- t.test(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")])
ttestLP
difinAUCLP <- cohensD(mean(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], na.rm = FALSE),
mean(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")], na.rm = FALSE),
sd(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], na.rm = FALSE),
sd(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")], na.rm = FALSE),
nLP,
nLP)
difinAUCLP
ttestLP
difinAUCLP <- cohensD(mean(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], na.rm = FALSE),
mean(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")], na.rm = FALSE),
sd(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], na.rm = FALSE),
sd(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")], na.rm = FALSE),
nLP,
nLP)
difinAUCLP
jsq::bttestIS(formula = AUC ~ b1_timingCond, data = AUCResults, hypothesis = "oneGreater", desc = TRUE)
describeBy(AUCResults$AUC, AUCResults$b1_timingCond)
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIcongruentLPBoot
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIcongruentLPBoot
CIincongruentHPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")])
CIincongruentHPBoot
AUCResults <- merge(grpAUC, dataSummary, by.x = "IDs")
table(AUCResults$b1_timingCond)
nHP <- as.numeric(table(AUCResults$b1_timingCond)[1])
nLP <- as.numeric(table(AUCResults$b1_timingCond)[2])
describeBy(AUCResults$AUC, AUCResults$b1_timingCond)
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIcongruentLPBoot
describeBy(AUCResults$AUC, AUCResults$b1_timingCond)
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIcongruentLPBoot
CIincongruentHPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")])
CIincongruentHPBoot
CIcongruentLPBoot
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIcongruentLPBoot
# AUC smaller than 2.16
AUCResults$smaller216 <- rep(0, nrow(AUCResults))
AUCResults$smaller216[which(AUCResults$AUC < 2.16)] <- 1
AUCResults$check <- AUCResults$AUC
AUCResults <- subset(AUCResults, AUCResults$smaller216 == 0 )
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIincongruentHPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")])
CIcongruentLPBoot
describeBy(AUCResults$AUC, AUCResults$b1_timingCond)
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")])
CIcongruentLPBoot
CIincongruentHPBoot <- calcCIBoot(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")])
CIincongruentHPBoot
describeBy(AUCResults$AUC, AUCResults$b1_timingCond)
# compare behavior in LP to optimal behavior (selling just after 2.16)
t.test(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], mu = 2.16)
t.test(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")], mu = 2.16)
cohdeviation_congruent <- (mean(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], na.rm = FALSE) - 2.16) / sd(AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")], na.rm = FALSE)
cohdeviation_incongruent <- (mean(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")], na.rm = FALSE) - 2.16) / sd(AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")], na.rm = FALSE)
# Mean survival curves by condition
# set up colors for group plots
colLPbk1 <- rgb(225, 0, 0, max = 255, alpha = 125)
colHPbk1 <- rgb(255,105,180, max = 255, alpha = 125)
colLPbk1_transp = rgb(225, 0, 0, max = 255, alpha = 70)
colHPbk1_transp <- rgb(255,105,180, max = 255, alpha = 50)
colGray = rgb(1/3, 1/3, 1/3)
LP_ids <- AUCResults$IDs[which(AUCResults$b1_timingCond == "LP")]
HP_ids <- AUCResults$IDs[which(AUCResults$b1_timingCond == "HP")]
# plot group mean survival curves for block 1 (w/ SEM)
survCurve_grpMean_LPbk1 = colMeans2(grpSurvCurves[LP_ids, ])
survCurve_grpSEM_LPbk1 = colSds(grpSurvCurves[LP_ids, ]) / sqrt(length(LP_ids))
survCurve_grpMean_HPbk1 = colMeans2(grpSurvCurves[HP_ids, ])
survCurve_grpSEM_HPbk1 = colSds(grpSurvCurves[HP_ids, ]) / sqrt(length(HP_ids))
plot('', bty='n', xlab='Elapsed time in trial (s)', xlim=c(0,20), xaxp=c(0, 20, 4),
ylab='Survival rate', ylim=c(0,1), yaxp=c(0, 1, 2),
main='Survival curves by condition', las=1, xaxt='n')
axis(side = 1, at=seq(0,20, 10), las=1)
errorBand(xData=scGrid, yData=survCurve_grpMean_LPbk1, yErr=survCurve_grpSEM_LPbk1, bandColor=colLPbk1_transp)
errorBand(xData=scGrid, yData=survCurve_grpMean_HPbk1, yErr=survCurve_grpSEM_HPbk1, bandColor=colHPbk1_transp)
lines(scGrid, survCurve_grpMean_LPbk1, type='l', lwd=3, col=colLPbk1)
lines(scGrid, survCurve_grpMean_HPbk1, type='l', lwd=3, col=colHPbk1)
# add a legend
legend('topright',
legend=c('LP congruent', 'LP incongruent'),
col=c(colLPbk1, colHPbk1), bty='n', lwd=c(2, 2))
# beeswarm+box plot of group AUC results - between-subject effect for block 1
AUCList = list(
bk1LP = AUCResults$AUC[which(AUCResults$b1_timingCond == "LP")],
bk1HP = AUCResults$AUC[which(AUCResults$b1_timingCond == "HP")])
boxplot(AUCList, outline=FALSE, boxwex=0.5, col=c(colLPbk1_transp, colHPbk1_transp),
frame.plot=FALSE, boxlty=c('solid', 'dashed'), whisklty='blank', staplelty='blank',
boxcol=colGray, medcol=colGray,
xlab='Manipulation', ylim=c(0,30), yaxp=c(0, 30, 4), ylab='AUC (s)',
main='AUC')
beeswarm(AUCList, pch=16, col=c(colLPbk1, colHPbk1), bty='n', cex=0.9, spacing=0.9, method='compactswarm',
add=TRUE, axes=FALSE)
# end figure
# WTW time series, across both conditions
tGrid = 1:600 # Note this this is only 600 seconds
wtwTS_results = matrix(data=NA, nrow=n, ncol=length(tGrid), dimnames=list(allIDs))
wtwCeiling=20
# "R_2D8h2RTudkW1Iul" sold the last token in block 2 at 600.001, this causes issues in the next calculations, so I will manually set it to 600.
large_df$n_sell_time_fin[which(large_df$n_sell_time_fin == 600.001)] <- 600
for (id in dataSummary$ID) {
blockData <-  subset(large_df, large_df$subject_id == id & large_df$n_block == 2)
# calculate willingness to wait time-series
wtwTS_results[id, ] <- wtwTS(blockData, tGrid, wtwCeiling)
}
# plot the mean WTW function by counterbalance group
tValues = list(1:600)
# obtain mean and SEM for each counterbalance group
wtwTS_grpMean = list()
wtwTS_grpSEM = list()
for (this_cbal in c('HP', 'LP')) {
if (this_cbal == "HP"){
wtwTS_grpMean[[this_cbal]] = colMeans2(wtwTS_results[HP_ids, ])
wtwTS_grpSEM[[this_cbal]] = colSds(wtwTS_results[HP_ids, ])/sqrt(length(HP_ids))
}
if (this_cbal == "LP"){
wtwTS_grpMean[[this_cbal]] = colMeans2(wtwTS_results[LP_ids, ])
wtwTS_grpSEM[[this_cbal]] = colSds(wtwTS_results[LP_ids, ])/sqrt(length(LP_ids))
}
}
# regression model predicting WTW per second by seconds elapsed for each individual, then compare coefficients using a t-test
dataSummary$wtw_trend <- rep(NA, nrow(dataSummary))
for (id in dataSummary$ID) {
data <-  subset(large_df, large_df$subject_id == id)
wtwTS_vector <- wtwTS_results[id, ]
dat <- as.data.frame(cbind(1:600, wtwTS_vector))
colnames(dat) <- c("second", "wtw")
model <- lm(wtw ~ second, data = dat)
dataSummary$wtw_trend[which(dataSummary$IDs == id)] <- as.numeric(model$coefficients[2])
}
AUCResults <- merge(grpAUC, dataSummary, by.x = "IDs")
table(AUCResults$b1_timingCond)
nHP <- as.numeric(table(AUCResults$b1_timingCond)[1])
nLP <- as.numeric(table(AUCResults$b1_timingCond)[2])
describeBy(AUCResults$AUC, AUCResults$b1_timingCond)
AUCResults$smaller216 <- rep(0, nrow(AUCResults))
AUCResults$smaller216[which(AUCResults$AUC < 2.16)] <- 1
dataSummary$smaller216 <- AUCResults$smaller216
dataSummary$AUC <- AUCResults$AUC
describeBy(dataSummary$wtw_trend, dataSummary$b1_timingCond)
dataSummary <- subset(dataSummary, dataSummary$smaller216 == 0)
# means
mean(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "LP")])
mean(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "HP")])
# Bootstrap confidence interval for LP
CIcongruentLPBoot <- calcCIBoot(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "LP")])
CIincongruentLPBoot <- calcCIBoot(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "HP")])
# LP t-test and Bayes factor
ttestLP <- t.test(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "LP")], dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "HP")])
ttestLP
difintrendLP <- cohensD(mean(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "LP")], na.rm = FALSE),
mean(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "HP")], na.rm = FALSE),
sd(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "LP")], na.rm = FALSE),
sd(dataSummary$wtw_trend[which(dataSummary$b1_timingCond == "HP")], na.rm = FALSE),
nLP,
nHP)
difintrendLP
jsq::bttestIS(formula = wtw_trend ~ b1_timingCond, data = dataSummary, hypothesis = "oneGreater", desc = TRUE)
large_df$length_delay <- rep(0, nrow(large_df))
large_df$length_delay[which(as.numeric(large_df$n_scheduled_delay) < 3)] <- "less3"
large_df$length_delay[which(as.numeric(large_df$n_scheduled_delay) >= 3 & as.numeric(large_df$n_scheduled_delay) < 6)] <- "3to6"
large_df$length_delay[which(as.numeric(large_df$n_scheduled_delay) >= 6 & as.numeric(large_df$n_scheduled_delay) < 9)] <- "6to9"
large_df$length_delay[which(as.numeric(large_df$n_scheduled_delay) >= 9 & as.numeric(large_df$n_scheduled_delay) < 15)] <- "9to15"
large_df$length_delay[which(as.numeric(large_df$n_scheduled_delay) >= 15 & as.numeric(large_df$n_scheduled_delay) <= 20)] <- "15to20"
large_df$length_delay[which(as.numeric(large_df$n_scheduled_delay) > 20)] <- "exclude"
large_df$copydesignatedWait <- large_df$designatedWait # to check
dflmer <- c()
for (id in dataSummary$ID) {
data <-  subset(large_df, large_df$subject_id == id & large_df$n_block == 1)
data$secondHalf <- rep(0, nrow(data))
startSecondHalf <- (ceiling(nrow(data)/2)+1)
data$secondHalf[startSecondHalf:nrow(data)] <- 1
# create DV:The dependent variable is the RT on each trial after subtracting the grand median RT for each participant (across all trials in the first block).
data$medianRT <- rep(median(data$RT, na.rm = TRUE), nrow(data))
data$RTMinusMedianRT <- data$RT - data$medianRT
dflmer <- rbind(dflmer, data)
}
dflmer$n_time_waited_fin <- as.numeric(dflmer$n_time_waited_fin)
dflmer$n_RTMinusMedianRT <- as.numeric(dflmer$RTMinusMedianRT)
dflmer$n_scheduled_delay <- as.numeric(dflmer$n_scheduled_delay)
# only use second half for analysis
dflmer_incl <- subset (dflmer, dflmer$secondHalf == 1 & dflmer$n_scheduled_delay <= 20)
dflmer <- dflmer_incl
# Participants who experienced HP in block 1
dflmer_HP <- subset(dflmer, dflmer$f_timing_condition == "HP")
dflmer_LP <- subset(dflmer, dflmer$f_timing_condition == "LP")
# Model
model_HP <- lmer(n_RTMinusMedianRT ~ n_scheduled_delay + (1 + n_scheduled_delay | subject_id), data =  dflmer_HP, control = lmerControl(optimizer = c("bobyqa")))
summary(model_HP)
model_LP <- lmer(n_RTMinusMedianRT ~ n_scheduled_delay + (1 + n_scheduled_delay | subject_id), data =  dflmer_LP, control = lmerControl(optimizer = c("bobyqa")))
summary(model_LP)
setwd("~/Documents/GitHub/wtw-Penn-BU-collab/wtw-temporal-information/Open material/Analysis scripts")
# Load libraries
library('tcltk')
library('survival')
library('lattice')
library('ggplot2')
library('psych')
library('jtools')
source('wtwFxs.R')
library('matrixStats')
library('beeswarm')
library("jtools")
library("lme4")
library("lsr")
library("BayesFactor")
library("here")
# Set data directory
dataDir <- "../study 3b/data"
setwd(dataDir)
# select and load all data files
file.names <- list.files(pattern = "*_data.csv")
# will load all data files in a list named "df,list"- each file can be accessed using df.list[[d]]
df.list <- lapply(file.names, function(file.name)
{
df           <- read.csv(file.name)
df$file.name <- file.name
return(df)
})
length(df.list) # number of participants in the list
# check the loaded data files and save out a summary
# data_summary: Should have basic information on each participant, such as
# ID, date of participation, condition, number of trials, duration, and a check for the inclusion criteria
IDs <- c()
numTrials <- c()
timingCond <- c()
lastSellTime <- c() # last token sold in the block
earnings <- c()
date <- c()
manipulation <- c()
medianRT <- c()
RTSumAboveOne <- c()
maxSchedueldDelay <- c()
medianRTCheck <- c()
RTSumAboveOneCheck <- c()
lastSellTimeCheck <- c()
file_name <- c()
for (d in 1:length(df.list)){
data <- df.list[[d]]
IDs <- c(IDs, data$subject_id[1])
numTrials <- c(numTrials, as.numeric(max(data$n_trialIdx)))
timingCond <- c(timingCond, data$f_timing_condition[1])
lastSellTime <- c(lastSellTime, max(data$n_sell_time))
earnings <- c(earnings, max(data$n_total_earnings))
manipulation <- c(manipulation, data$condition[1])
date <- c(date, substr(data$file_name[1], start = 42, stop = 51))
file_name <- c(file_name, data$file_name[1])
medianRT <- c(medianRT, median( data$RT, na.rm = T))
maxSchedueldDelay <- c(maxSchedueldDelay, max(data$n_scheduled_delay))
# Prepare for check of exclusion criteria
### Participants will be excluded if they fail to complete the entire WTW task.
if (lastSellTime[d] <= 900 - 60){
lastSellTimeCheck <- c(lastSellTimeCheck, 0)
print("Warning: This participant did not complete the whole task.")
} else if (lastSellTime[d] > 900 - 60){
lastSellTimeCheck <- c(lastSellTimeCheck, 1)
}
### Participants will be excluded if they were too slow to sell tokens that had matured and delivered rewards. We will calculate the per-session median response time (RT) to sell rewarded tokens (combining both task blocks in the session). The participant’s WTW task data will be excluded if the median RT exceeds a threshold of 1.25 s
if (medianRT[d] >= 1.25){
medianRTCheck <- c(medianRTCheck, 0)
print("Warning: This participants median RT is equal to or higher than 1.25.")
} else if (medianRT[d] < 1.25){
medianRTCheck <- c(medianRTCheck, 1)
}
### Participants will be excluded on the basis of a cumulative measure of “off-task time” per block. Off-task time will include time in excess of 1 s on a given trial between the delivery of a reward (a matured token) and the participant’s “sell” response to collect the reward. For example, selling a rewarded token with an RT of 2 s would add 1 s to the block’s off-task time, and selling a rewarded token with an RT of 500 ms would have no effect on the block’s off-task time. A participant’s WTW task data will be excluded if they accumulate 180 s or more of off-task time during the 15-minute block (more than 20% off-task time).
# investigate all RTs that are longer than 1 second
idx <- which(data$RT > 1)
if (length(idx) == 0){
RTSumAboveOneValue <- 0
RTSumAboveOne <- c(RTSumAboveOne, RTSumAboveOneValue)
}  else {
exceeded_1s <- data$RT[idx] - 1
RTSumAboveOneValue <- sum(exceeded_1s)
if (as.numeric(RTSumAboveOneValue) >= 180){
RTSumAboveOne <- c(RTSumAboveOne, RTSumAboveOneValue)
} else {
RTSumAboveOne <- c(RTSumAboveOne, RTSumAboveOneValue)
}
}
if (RTSumAboveOne[d] >= 180){
RTSumAboveOneCheck <- c(RTSumAboveOneCheck, 0)
print("Warning: This participant spend more than 180s off-task.")
} else if (RTSumAboveOne[d] < 180){
RTSumAboveOneCheck <- c(RTSumAboveOneCheck, 1)
}
# add quit index to each data set, 1 refers to a quit
df.list[[d]]$idxQuit <- rep(0, nrow(df.list[[d]]))
df.list[[d]]$idxQuit[which(is.na(df.list[[d]]$n_rewarded_time))] <- 1
}
dataSummary <- as.data.frame(cbind(IDs, date, file_name, numTrials, earnings, timingCond, manipulation, maxSchedueldDelay, lastSellTime, lastSellTimeCheck, medianRT, medianRTCheck, RTSumAboveOne, RTSumAboveOneCheck))
# turn df.list into a data file - easier for processing below
large_df <- do.call(rbind.data.frame, df.list)
# explore exclusion criteria
exclusion_data <- as.data.frame(cbind(dataSummary$IDs, dataSummary$lastSellTime, dataSummary$lastSellTimeCheck, dataSummary$medianRT, dataSummary$medianRTCheck, dataSummary$RTSumAboveOne, dataSummary$RTSumAboveOneCheck))
colnames(exclusion_data) <- c("IDs", "lastSellTimeC", "lastSellTimeCheck", "medianRT", "medianRTCheck", "RTSumAboveOne", "RTSumAboveOneCheck")
exclusion_data$lastSellTimeCheck <- as.numeric(exclusion_data$lastSellTimeCheck)
exclusion_data$medianRTCheck <- as.numeric(exclusion_data$medianRTCheck)
exclusion_data$RTSumAboveOneCheck <- as.numeric(exclusion_data$RTSumAboveOneCheck)
sum(exclusion_data$lastSellTimeCheck)
sum(exclusion_data$medianRTCheck)
sum(exclusion_data$RTSumAboveOneCheck)
# Exclude using criteria
exclusion_data <- subset (exclusion_data,
exclusion_data$RTSumAboveOneCheck == 1 &
exclusion_data$medianRTCheck == 1 &
exclusion_data$lastSellTimeCheck == 1)
# Exclude the two last participants that were collected in discrete (please find further information at the end of this script)
exclusion_data <- subset (exclusion_data, exclusion_data$IDs != "R_2WBau1gIw3CxKHC" & exclusion_data$IDs != "R_3EWM6hxYK9WZmCf")
# number of included data sets
nrow(exclusion_data)
# preliminary stuff
allIDs = exclusion_data$IDs # included IDs
n = length(allIDs)
# remove excluded participants from data files
dataSummary <- droplevels(dataSummary[dataSummary$ID %in% allIDs, ])
large_df <- droplevels(large_df[large_df$subject_id %in% allIDs, ])
nrow(dataSummary)
# Set figure directory
figDir <- "../output"
setwd(figDir)
study <- "3b"
# Set figure directory
figDir <- "../output"
setwd(figDir)
study <- "3b"
# plot the distribution of scheduled delays in each block (ECDF)
figName = file.path(sprintf('indivs_n%d_scheduledDelaysECDF.pdf', n)) # adjust ECDF
pdf(figName, width=6, height=3*n, pointsize=14)
layout(matrix(1:n, n, 1))
for (id in dataSummary$ID) {
blockData <-  subset(large_df, large_df$subject_id == id)
scheduledDelaysECDF(blockData, study, id, dataSummary)
}
dev.off()
# plot the distribution of scheduled delays in each block (ACF)
figName = file.path(sprintf('indivs_n%d_scheduledDelaysACF.pdf', n))
pdf(figName, width=6, height=3*n, pointsize=14)
layout(matrix(1:n, n, 1))
for (id in dataSummary$ID) {
blockData <-  subset(large_df, large_df$subject_id == id)
scheduledDelaysACF(blockData, study, id, dataSummary)
}
dev.off()
# reaction time plot
figName = file.path(sprintf('indivs_n%d_RT.pdf', n))
pdf(figName, width=6, height=3*n, pointsize=14)
layout(matrix(1:n, n, 1))
for (id in dataSummary$ID) {
blockData <-  subset(large_df, large_df$subject_id == id)
outcomeRT(blockData, study, id, dataSummary)
}
dev.off()
# plot trial-by-trial data
figName = file.path(sprintf('indivs_n%d_trialPlots.pdf', n))
pdf(figName, width=6, height=3*n, pointsize=14)
layout(matrix(1:n, n, 1))
for (id in dataSummary$ID) {
blockData <-  subset(large_df, large_df$subject_id == id)
trialPlots(blockData, study, id, dataSummary)
}
dev.off()
# survival curve and AUC
grpAUC = data.frame(rownames=dataSummary$ID, IDs=dataSummary$ID, AUC=numeric(n),
row.names='rownames', stringsAsFactors=FALSE) # initialize group results
scGrid = seq(0, 20, by=0.1)
grpSurvCurves = matrix(nrow=n, ncol=length(scGrid), dimnames=list(dataSummary$ID, scGrid)) # initialize
figName = file.path(figDir, sprintf('indivs_n%d_survivalCurves.pdf', n))
pdf(figName, width=6, height=3*n, pointsize=14)
layout(matrix(1:n, n, 1))
for (id in dataSummary$ID) {
blockData <-  subset(large_df, large_df$subject_id == id)
# calculate kaplan-meier survival curve and area under the curve
output <- kmsc(blockData, study, id, dataSummary, scGrid)
grpAUC$AUC[which(grpAUC$IDs == id)] = output$auc
grpSurvCurves[id, ] = output$kmOnGrid
}
dev.off()
AUCResults <- merge(grpAUC, dataSummary, by.x = "IDs")
table(AUCResults$manipulation) # 80 participants per group
describeBy(AUCResults$AUC, AUCResults$manipulation) # descriptive information
AUCResults$smaller216 <- rep(0, nrow(AUCResults))
AUCResults$smaller216[which(AUCResults$AUC < 2.16)] <- 1
dataSummary$smaller216 <- AUCResults$smaller216
dataSummary$AUC <- AUCResults$AUC
AUCResults$check <- AUCResults$AUC
AUCResults <- subset(AUCResults, AUCResults$smaller216 == 0 )
View(AUCResults)
describeBy(AUCResults$AUC, AUCResults$manipulation) # descriptive information
# T-test and Bayes factor
ttest <- t.test(AUCResults$AUC ~ AUCResults$manipulation)
ttest
difinAUC <- cohensD(mean(AUCResultsStandard$AUC, na.rm = FALSE),
mean(AUCResultsDiscrete$AUC, na.rm = FALSE),
sd(AUCResultsStandard$AUC, na.rm = FALSE),
sd(AUCResultsDiscrete$AUC, na.rm = FALSE),
80,
80)
AUCResultsStandard <- subset(AUCResults, AUCResults$manipulation == "standard")
AUCResultsDiscrete <- subset(AUCResults, AUCResults$manipulation == "discrete")
# Find the confidence interval (set to 95%) using bootstrapping
CIstandardBoot <- calcCIBoot(AUCResultsStandard$AUC)
CIdiscreteBoot <- calcCIBoot(AUCResultsDiscrete$AUC)
difinAUC <- cohensD(mean(AUCResultsStandard$AUC, na.rm = FALSE),
mean(AUCResultsDiscrete$AUC, na.rm = FALSE),
sd(AUCResultsStandard$AUC, na.rm = FALSE),
sd(AUCResultsDiscrete$AUC, na.rm = FALSE),
80,
80)
difinAUC
# WTW time series, across both conditions
tGrid = 1:900
wtwCeiling=20 # for comparability across studies/conditions
wtwTS_results = matrix(data=NA, nrow=n, ncol=length(tGrid), dimnames=list(allIDs))
wtwTS_slope = data.frame(ID=allIDs, Block1=rep(NA,n), LP=rep(NA,n),
row.names=allIDs, stringsAsFactors=FALSE)
for (id in dataSummary$ID) {
blockData <-  subset(large_df, large_df$subject_id == id)
# calculate willingness to wait time-series
wtwTS_results[id, ] <- wtwTS(blockData, tGrid, wtwCeiling)
}
# plot the mean WTW function by counterbalance group
tValues = list(1:900)
# obtain mean and SEM for each counterbalance group
wtwTS_grpMean = list()
wtwTS_grpSEM = list()
for (this_cbal in c('LPStandard', 'LPDiscrete')) {
if (this_cbal == "LPStandard"){
wtwTS_grpMean[[this_cbal]] = colMeans2(wtwTS_results[standard_ids, ])
wtwTS_grpSEM[[this_cbal]] = colSds(wtwTS_results[standard_ids, ])/sqrt(length(standard_ids))
}
if (this_cbal == "LPDiscrete"){
wtwTS_grpMean[[this_cbal]] = colMeans2(wtwTS_results[discrete_ids, ])
wtwTS_grpSEM[[this_cbal]] = colSds(wtwTS_results[discrete_ids, ])/sqrt(length(discrete_ids))
}
}
figName = file.path(figDir, sprintf('n%d_wtwByCondition.pdf', n))
pdf(figName, width=6, height=3, pointsize=9)
# figName = file.path(sprintf('n%d_wtwByConditionLP.tiff', n))
# tiff(figName, units="in", width=10, height=5, res=300)
# initialize the plot
plot('', type='n', xlim=c(0, 900), bty='n', ylim=c(0, 20), yaxp=c(0, 20, 4),
xlab='Time elapsed in block (min)', ylab='WTW (s)',
main='Local willingness-to-wait estimates', yaxt='n', xaxt='n')
axis(side = 2, at=seq(0,30, 10), las=1)
axis(side = 1, at=seq(0, 960, 120), las=1, labels = seq(0, 16, 2))
# add error bands, one block at a time
errorBand(xData=1:900, yData=wtwTS_grpMean$LPStandard,
yErr=wtwTS_grpSEM$LPStandard, bandColor=colLPStandard_transp)
errorBand(xData=1:900, yData=wtwTS_grpMean$LPDiscrete,
yErr=wtwTS_grpSEM$LPDiscrete, bandColor=colLPDiscrete_transp)
# add means
lines(1:900, wtwTS_grpMean$LPStandard, col=colLPStandard, type='l', lwd=2, lty='solid')
lines(1:900, wtwTS_grpMean$LPDiscrete, col=colLPDiscrete, type='l', lwd=2, lty='solid')
# add a legend
legend('topright',
legend=c('LP standard', 'LP instructed'),
col=c(colLPStandard, colLPDiscrete), bty='n', lwd=c(2, 2))
dev.off()
# regression model predicting WTW per second by seconds elapsed for each individual, then compare coefficients using a t-test
dataSummary$wtw_trend <- rep(NA, nrow(dataSummary))
for (id in dataSummary$ID) {
data <-  subset(large_df, large_df$subject_id == id)
wtwTS_vector <- wtwTS_results[id, ]
dat <- as.data.frame(cbind(1:900, wtwTS_vector))
colnames(dat) <- c("second", "wtw")
model <- lm(wtw ~ second, data = dat)
dataSummary$wtw_trend[which(dataSummary$IDs == id)] <- as.numeric(model$coefficients[2])
}
View(dataSummary)
dataSummary <- subset(dataSummary, dataSummary$smaller216 == 0)
describeBy(dataSummary$wtw_trend, dataSummary$manipulation)
# LP t-test and Bayes factor
ttestLP <- t.test(dataSummary$wtw_trend[which(dataSummary$manipulation == "standard")], dataSummary$wtw_trend[which(dataSummary$manipulation == "discrete")])
ttestLP
